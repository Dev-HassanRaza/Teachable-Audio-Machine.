<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voice Detection Model</title>
  </head>
  <style>
    * {
      /* background-color: black; */
    }
    .header {
      color: rgb(0, 0, 0);
      text-align: center;
      justify-content: center;
      font-size: xx-large;
    }
    .btn-start {
      font-size: 50px;
      border-radius: 12px;
      border: none;
      background-color: white;
      cursor: pointer;
    }
    .btn-start:hover {
      background-color: black;
      color: white;
      transition: 0.8s;
    }
    #label-container {
      font-size: 50px;
    }
  </style>
  <body>
    <br /><br /><br /><br /><br /><br /><br /><br /><br />
    <center>
      <div class="header">Testing Model For Voice Detection</div>
      <button class="btn-start" type="button" onclick="init()">Start</button>
      <div id="webcam-container"></div>
      <div id="label-container"></div>
    </center>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>

    <script type="text/javascript">
      // more documentation available at
      // https://github.com/tensorflow/tfjs-models/tree/master/speech-commands

      // the link to your model provided by Teachable Machine export panel
      const URL = "https://teachablemachine.withgoogle.com/models/7qdvsIVwe/";

      async function createModel() {
        const checkpointURL = URL + "model.json"; // model topology
        const metadataURL = URL + "metadata.json"; // model metadata

        const recognizer = speechCommands.create(
          "BROWSER_FFT", // fourier transform type, not useful to change
          undefined, // speech commands vocabulary feature, not useful for your models
          checkpointURL,
          metadataURL
        );

        // check that model and metadata are loaded via HTTPS requests.
        await recognizer.ensureModelLoaded();

        return recognizer;
      }

      async function init() {
        const recognizer = await createModel();
        const classLabels = recognizer.wordLabels(); // get class labels
        const labelContainer = document.getElementById("label-container");
        for (let i = 0; i < classLabels.length; i++) {
          labelContainer.appendChild(document.createElement("div"));
        }

        // listen() takes two arguments:
        // 1. A callback function that is invoked anytime a word is recognized.
        // 2. A configuration object with adjustable fields
        recognizer.listen(
          (result) => {
            const scores = result.scores; // probability of prediction for each class
            // render the probability scores per class
            for (let i = 0; i < classLabels.length; i++) {
              const classPrediction =
                classLabels[i] + ": " + result.scores[i].toFixed(2);
              labelContainer.childNodes[i].innerHTML = classPrediction;
            }
          },
          {
            includeSpectrogram: true, // in case listen should return result.spectrogram
            probabilityThreshold: 0.75,
            invokeCallbackOnNoiseAndUnknown: true,
            overlapFactor: 0.5, // probably want between 0.5 and 0.75. More info in README
          }
        );

        // Stop the recognition in 5 seconds.
        // setTimeout(() => recognizer.stopListening(), 5000);
      }
    </script>
  </body>
</html>
